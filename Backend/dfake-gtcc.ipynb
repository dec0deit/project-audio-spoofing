{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b4a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization,Conv2D,MaxPooling2D,Activation,Dropout,Dense,Flatten,Input,Bidirectional,LSTM,MaxPool2D\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, balanced_accuracy_score, classification_report\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, SimpleRNN, LSTM, TimeDistributed, Flatten, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b7b3575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-0.55307</th>\n",
       "      <th>-15.772</th>\n",
       "      <th>3.4207</th>\n",
       "      <th>0.33526</th>\n",
       "      <th>0.89613</th>\n",
       "      <th>0.088091</th>\n",
       "      <th>0.41567</th>\n",
       "      <th>0.1267</th>\n",
       "      <th>0.13255</th>\n",
       "      <th>0.33759</th>\n",
       "      <th>...</th>\n",
       "      <th>2.4793e-05</th>\n",
       "      <th>-2.572e-05</th>\n",
       "      <th>2.7463e-05</th>\n",
       "      <th>-0.00010205</th>\n",
       "      <th>6.3365e-05</th>\n",
       "      <th>0.00011715</th>\n",
       "      <th>8.8406e-05</th>\n",
       "      <th>0.00023632</th>\n",
       "      <th>6.1803e-05</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.33518</td>\n",
       "      <td>-16.053</td>\n",
       "      <td>3.4372</td>\n",
       "      <td>0.538450</td>\n",
       "      <td>1.16200</td>\n",
       "      <td>0.104200</td>\n",
       "      <td>0.550410</td>\n",
       "      <td>0.078066</td>\n",
       "      <td>0.116910</td>\n",
       "      <td>0.323680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000381</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>6.636000e-05</td>\n",
       "      <td>-0.000321</td>\n",
       "      <td>-8.702900e-05</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.53979</td>\n",
       "      <td>-16.520</td>\n",
       "      <td>3.8842</td>\n",
       "      <td>0.345140</td>\n",
       "      <td>1.06500</td>\n",
       "      <td>0.030910</td>\n",
       "      <td>0.511500</td>\n",
       "      <td>0.167270</td>\n",
       "      <td>0.065071</td>\n",
       "      <td>0.384900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-1.515600e-05</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-1.839500e-05</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.96780</td>\n",
       "      <td>-17.320</td>\n",
       "      <td>3.4535</td>\n",
       "      <td>0.423470</td>\n",
       "      <td>1.11510</td>\n",
       "      <td>0.163320</td>\n",
       "      <td>0.463380</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.251330</td>\n",
       "      <td>0.265720</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-1.758800e-05</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>5.107700e-05</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.12280</td>\n",
       "      <td>-14.837</td>\n",
       "      <td>3.3643</td>\n",
       "      <td>0.459630</td>\n",
       "      <td>0.52199</td>\n",
       "      <td>-0.105580</td>\n",
       "      <td>0.114080</td>\n",
       "      <td>-0.053301</td>\n",
       "      <td>0.128630</td>\n",
       "      <td>0.130330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>-0.000110</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-2.032300e-04</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-6.727600e-05</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.32150</td>\n",
       "      <td>-14.409</td>\n",
       "      <td>3.1191</td>\n",
       "      <td>0.420480</td>\n",
       "      <td>0.63160</td>\n",
       "      <td>-0.177200</td>\n",
       "      <td>0.153630</td>\n",
       "      <td>-0.026331</td>\n",
       "      <td>0.007912</td>\n",
       "      <td>-0.141600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-1.419000e-04</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1.348700e-04</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>-8.59160</td>\n",
       "      <td>-26.017</td>\n",
       "      <td>2.5447</td>\n",
       "      <td>0.162820</td>\n",
       "      <td>0.66613</td>\n",
       "      <td>0.192750</td>\n",
       "      <td>-0.028030</td>\n",
       "      <td>0.128970</td>\n",
       "      <td>0.184560</td>\n",
       "      <td>0.075373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>-4.541800e-05</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-5.652000e-05</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>-7.60430</td>\n",
       "      <td>-24.992</td>\n",
       "      <td>2.4934</td>\n",
       "      <td>0.019378</td>\n",
       "      <td>1.07950</td>\n",
       "      <td>0.118580</td>\n",
       "      <td>-0.020449</td>\n",
       "      <td>0.490060</td>\n",
       "      <td>-0.054519</td>\n",
       "      <td>-0.100330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-7.326100e-05</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>-6.769900e-07</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>-7.48440</td>\n",
       "      <td>-24.849</td>\n",
       "      <td>2.2581</td>\n",
       "      <td>0.087262</td>\n",
       "      <td>1.27940</td>\n",
       "      <td>0.087433</td>\n",
       "      <td>-0.099659</td>\n",
       "      <td>0.511090</td>\n",
       "      <td>-0.008054</td>\n",
       "      <td>-0.118260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>-3.127800e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-1.128000e-04</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>-7.49000</td>\n",
       "      <td>-24.807</td>\n",
       "      <td>2.5908</td>\n",
       "      <td>-0.008090</td>\n",
       "      <td>1.18920</td>\n",
       "      <td>0.079559</td>\n",
       "      <td>-0.101770</td>\n",
       "      <td>0.540110</td>\n",
       "      <td>-0.074005</td>\n",
       "      <td>-0.081330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000110</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>-1.266300e-04</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>5.600200e-05</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>-7.23920</td>\n",
       "      <td>-24.575</td>\n",
       "      <td>2.5757</td>\n",
       "      <td>-0.065672</td>\n",
       "      <td>1.36830</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>-0.145120</td>\n",
       "      <td>0.579540</td>\n",
       "      <td>-0.089406</td>\n",
       "      <td>-0.086505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>5.736900e-05</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>8.620400e-05</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2999 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      -0.55307  -15.772  3.4207   0.33526  0.89613  0.088091   0.41567  \\\n",
       "0     -0.33518  -16.053  3.4372  0.538450  1.16200  0.104200  0.550410   \n",
       "1     -0.53979  -16.520  3.8842  0.345140  1.06500  0.030910  0.511500   \n",
       "2     -0.96780  -17.320  3.4535  0.423470  1.11510  0.163320  0.463380   \n",
       "3      1.12280  -14.837  3.3643  0.459630  0.52199 -0.105580  0.114080   \n",
       "4      1.32150  -14.409  3.1191  0.420480  0.63160 -0.177200  0.153630   \n",
       "...        ...      ...     ...       ...      ...       ...       ...   \n",
       "2994  -8.59160  -26.017  2.5447  0.162820  0.66613  0.192750 -0.028030   \n",
       "2995  -7.60430  -24.992  2.4934  0.019378  1.07950  0.118580 -0.020449   \n",
       "2996  -7.48440  -24.849  2.2581  0.087262  1.27940  0.087433 -0.099659   \n",
       "2997  -7.49000  -24.807  2.5908 -0.008090  1.18920  0.079559 -0.101770   \n",
       "2998  -7.23920  -24.575  2.5757 -0.065672  1.36830  0.040816 -0.145120   \n",
       "\n",
       "        0.1267   0.13255   0.33759  ...  2.4793e-05  -2.572e-05  2.7463e-05  \\\n",
       "0     0.078066  0.116910  0.323680  ...    0.000210    0.000191   -0.000381   \n",
       "1     0.167270  0.065071  0.384900  ...   -0.000042   -0.000052    0.000064   \n",
       "2     0.229270  0.251330  0.265720  ...   -0.000029   -0.000031   -0.000005   \n",
       "3    -0.053301  0.128630  0.130330  ...   -0.000220   -0.000110   -0.000154   \n",
       "4    -0.026331  0.007912 -0.141600  ...   -0.000019    0.000075    0.000083   \n",
       "...        ...       ...       ...  ...         ...         ...         ...   \n",
       "2994  0.128970  0.184560  0.075373  ...    0.000117    0.000025   -0.000070   \n",
       "2995  0.490060 -0.054519 -0.100330  ...   -0.000022    0.000080    0.000185   \n",
       "2996  0.511090 -0.008054 -0.118260  ...    0.000120    0.000201    0.000014   \n",
       "2997  0.540110 -0.074005 -0.081330  ...   -0.000110    0.000024    0.000117   \n",
       "2998  0.579540 -0.089406 -0.086505  ...   -0.000008    0.000093    0.000284   \n",
       "\n",
       "      -0.00010205  6.3365e-05    0.00011715  8.8406e-05    0.00023632  \\\n",
       "0       -0.000145    0.000409  6.636000e-05   -0.000321 -8.702900e-05   \n",
       "1        0.000126    0.000004 -1.515600e-05    0.000007 -1.839500e-05   \n",
       "2       -0.000019   -0.000012 -1.758800e-05   -0.000034  5.107700e-05   \n",
       "3        0.000078   -0.000050 -2.032300e-04    0.000005 -6.727600e-05   \n",
       "4        0.000076   -0.000028 -1.419000e-04    0.000058  1.348700e-04   \n",
       "...           ...         ...           ...         ...           ...   \n",
       "2994     0.000081    0.000137 -4.541800e-05   -0.000026 -5.652000e-05   \n",
       "2995    -0.000046    0.000009 -7.326100e-05   -0.000192 -6.769900e-07   \n",
       "2996    -0.000107   -0.000094 -3.127800e-07    0.000013 -1.128000e-04   \n",
       "2997     0.000019    0.000055 -1.266300e-04   -0.000162  5.600200e-05   \n",
       "2998     0.000183   -0.000139  5.736900e-05    0.000005  8.620400e-05   \n",
       "\n",
       "      6.1803e-05  0  \n",
       "0       0.000136  0  \n",
       "1      -0.000071  0  \n",
       "2       0.000034  0  \n",
       "3       0.000006  0  \n",
       "4       0.000066  0  \n",
       "...          ... ..  \n",
       "2994   -0.000065  0  \n",
       "2995   -0.000057  0  \n",
       "2996   -0.000165  0  \n",
       "2997    0.000062  0  \n",
       "2998    0.000026  0  \n",
       "\n",
       "[2999 rows x 43 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('C:\\\\Users\\\\singl\\\\OneDrive\\\\Documents\\\\MATLAB\\\\frontend\\\\M_TRAIN2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "630ee8e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'add'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9036/2501979507.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m39\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m39\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'add'"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, 0:39].values\n",
    "X.add(df1.iloc[:, 0:39].values)\n",
    "y = df.iloc[:,-1].values\n",
    "y.add(df1.iloc[:, -1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b90d6a0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The target 'y' needs to have more than 1 class. Got 1 class instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9036/319553228.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moversample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moversample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         self.sampling_strategy_ = check_sampling_strategy(\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampling_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py\u001b[0m in \u001b[0;36mcheck_sampling_strategy\u001b[1;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    501\u001b[0m             \u001b[1;34mf\"The target 'y' needs to have more than 1 class. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[1;34mf\"Got {np.unique(y).size} class instead\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The target 'y' needs to have more than 1 class. Got 1 class instead"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1510f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8a81ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45600, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d719c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc4af1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.reshape(45600,13,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b697b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e4451b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4560/4560 [==============================] - 33s 7ms/step - loss: 0.1606 - accuracy: 0.7620\n",
      "Epoch 2/50\n",
      "4560/4560 [==============================] - 39s 9ms/step - loss: 0.1297 - accuracy: 0.8102\n",
      "Epoch 3/50\n",
      "4560/4560 [==============================] - 41s 9ms/step - loss: 0.1081 - accuracy: 0.8490\n",
      "Epoch 4/50\n",
      "4560/4560 [==============================] - 42s 9ms/step - loss: 0.0831 - accuracy: 0.8898\n",
      "Epoch 5/50\n",
      "4560/4560 [==============================] - 43s 10ms/step - loss: 0.0613 - accuracy: 0.9211\n",
      "Epoch 6/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0536 - accuracy: 0.9304\n",
      "Epoch 7/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0477 - accuracy: 0.9398\n",
      "Epoch 8/50\n",
      "4560/4560 [==============================] - 43s 9ms/step - loss: 0.0443 - accuracy: 0.9435\n",
      "Epoch 9/50\n",
      "4560/4560 [==============================] - 45s 10ms/step - loss: 0.0415 - accuracy: 0.9481\n",
      "Epoch 10/50\n",
      "4560/4560 [==============================] - 47s 10ms/step - loss: 0.0394 - accuracy: 0.9508\n",
      "Epoch 11/50\n",
      "4560/4560 [==============================] - 48s 11ms/step - loss: 0.0365 - accuracy: 0.9545\n",
      "Epoch 12/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0350 - accuracy: 0.9569\n",
      "Epoch 13/50\n",
      "4560/4560 [==============================] - 43s 9ms/step - loss: 0.0327 - accuracy: 0.9601\n",
      "Epoch 14/50\n",
      "4560/4560 [==============================] - 43s 9ms/step - loss: 0.0324 - accuracy: 0.9609\n",
      "Epoch 15/50\n",
      "4560/4560 [==============================] - 43s 9ms/step - loss: 0.0311 - accuracy: 0.9612\n",
      "Epoch 16/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0295 - accuracy: 0.9648\n",
      "Epoch 17/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0291 - accuracy: 0.9645\n",
      "Epoch 18/50\n",
      "4560/4560 [==============================] - 43s 9ms/step - loss: 0.0281 - accuracy: 0.9660\n",
      "Epoch 19/50\n",
      "4560/4560 [==============================] - 43s 9ms/step - loss: 0.0277 - accuracy: 0.9665\n",
      "Epoch 20/50\n",
      "4560/4560 [==============================] - 46s 10ms/step - loss: 0.0264 - accuracy: 0.9688\n",
      "Epoch 21/50\n",
      "4560/4560 [==============================] - 45s 10ms/step - loss: 0.0257 - accuracy: 0.9695\n",
      "Epoch 22/50\n",
      "4560/4560 [==============================] - 45s 10ms/step - loss: 0.0251 - accuracy: 0.9700\n",
      "Epoch 23/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0248 - accuracy: 0.9704\n",
      "Epoch 24/50\n",
      "4560/4560 [==============================] - 43s 10ms/step - loss: 0.0243 - accuracy: 0.9712\n",
      "Epoch 25/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0238 - accuracy: 0.9717\n",
      "Epoch 26/50\n",
      "4560/4560 [==============================] - 43s 10ms/step - loss: 0.0233 - accuracy: 0.9730\n",
      "Epoch 27/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0229 - accuracy: 0.9731\n",
      "Epoch 28/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0229 - accuracy: 0.9731\n",
      "Epoch 29/50\n",
      "4560/4560 [==============================] - 43s 10ms/step - loss: 0.0224 - accuracy: 0.9736\n",
      "Epoch 30/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0216 - accuracy: 0.9747\n",
      "Epoch 31/50\n",
      "4560/4560 [==============================] - 45s 10ms/step - loss: 0.0212 - accuracy: 0.9757\n",
      "Epoch 32/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0211 - accuracy: 0.9757\n",
      "Epoch 33/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0205 - accuracy: 0.9763\n",
      "Epoch 34/50\n",
      "4560/4560 [==============================] - 43s 10ms/step - loss: 0.0199 - accuracy: 0.9775\n",
      "Epoch 35/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0200 - accuracy: 0.9766\n",
      "Epoch 36/50\n",
      "4560/4560 [==============================] - 43s 10ms/step - loss: 0.0196 - accuracy: 0.9771\n",
      "Epoch 37/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0198 - accuracy: 0.9767\n",
      "Epoch 38/50\n",
      "4560/4560 [==============================] - 43s 10ms/step - loss: 0.0193 - accuracy: 0.9780\n",
      "Epoch 39/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0190 - accuracy: 0.9783\n",
      "Epoch 40/50\n",
      "4560/4560 [==============================] - 43s 10ms/step - loss: 0.0194 - accuracy: 0.9775\n",
      "Epoch 41/50\n",
      "4560/4560 [==============================] - 43s 10ms/step - loss: 0.0182 - accuracy: 0.9797\n",
      "Epoch 42/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0183 - accuracy: 0.9793\n",
      "Epoch 43/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0185 - accuracy: 0.9789\n",
      "Epoch 44/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0177 - accuracy: 0.9798\n",
      "Epoch 45/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0175 - accuracy: 0.9801\n",
      "Epoch 46/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0173 - accuracy: 0.9801\n",
      "Epoch 47/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0168 - accuracy: 0.9811\n",
      "Epoch 48/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0168 - accuracy: 0.9808\n",
      "Epoch 49/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0172 - accuracy: 0.9809\n",
      "Epoch 50/50\n",
      "4560/4560 [==============================] - 44s 10ms/step - loss: 0.0167 - accuracy: 0.9806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d69b824dc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (13, 1)))\n",
    "\n",
    "#regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (67, 1)))\n",
    "\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics=['accuracy'])\n",
    "\n",
    "#regressor.fit(X_train, y_train, validation_data= (X_test,y_test),epochs = 50, batch_size = 32)\n",
    "regressor.fit(X, y, epochs = 50, batch_size = 10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ed38afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dtf=pd.read_csv('GFdfeval.csv')\n",
    "dtf\n",
    "Xt = dtf.iloc[:, 0:13].values\n",
    "\n",
    "yt = dtf.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45e8d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Xt = np.reshape(Xt, (Xt.shape[0], Xt.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76ea380f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nidhi Chakravarty\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "prediction1=regressor.predict_classes(Xt)\n",
    "#prediction1=regressor.predict((Xt) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f39c92df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 3ms/step - loss: 0.3326 - accuracy: 0.5817\n",
      "accuracy: 58.17%\n"
     ]
    }
   ],
   "source": [
    "score=regressor.evaluate(Xt, yt)\n",
    "print(\"%s: %.2f%%\" % (regressor.metrics_names[1], score[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1888512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix [[  29   45]\n",
      " [1079 1534]]\n",
      "Accuracy: 0.581690\n",
      "Precision: 0.971501\n",
      "Recall: 0.587065\n",
      "F1 score: 0.731870\n",
      "1\n",
      "EER =  0.4129353233830846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "results=confusion_matrix(yt, prediction1)\n",
    "print(\"confusion matrix\", results)\n",
    "\n",
    "accuracy = accuracy_score(yt, prediction1)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "precision = precision_score(yt, prediction1)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(yt, prediction1)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(yt, prediction1)\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(yt,prediction1, pos_label=1)\n",
    "fnr = 1 - tpr\n",
    "eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "EER = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "print(eer_threshold)\n",
    "print(\"EER = \", EER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a2b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(yt,prediction1, pos_label=1)\n",
    "fnr = 1 - tpr\n",
    "eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "EER = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "print(eer_threshold)\n",
    "print(\"EER = \", EER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3948af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
