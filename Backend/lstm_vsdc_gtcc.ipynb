{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b4a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization,Conv2D,MaxPooling2D,Activation,Dropout,Dense,Flatten,Input,Bidirectional,LSTM,MaxPool2D\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, balanced_accuracy_score, classification_report\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, SimpleRNN, LSTM, TimeDistributed, Flatten, Dropout, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b7b3575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-0.55307</th>\n",
       "      <th>-13.949</th>\n",
       "      <th>7.2276</th>\n",
       "      <th>0.81332</th>\n",
       "      <th>0.81042</th>\n",
       "      <th>0.57891</th>\n",
       "      <th>0.057156</th>\n",
       "      <th>0.30691</th>\n",
       "      <th>-0.28209</th>\n",
       "      <th>0.34901</th>\n",
       "      <th>...</th>\n",
       "      <th>-1.2757e-05</th>\n",
       "      <th>-1.791e-05</th>\n",
       "      <th>0.00014175</th>\n",
       "      <th>0.00018104</th>\n",
       "      <th>2.7085e-05</th>\n",
       "      <th>1.9801e-05</th>\n",
       "      <th>1.6102e-05</th>\n",
       "      <th>1.5949e-05</th>\n",
       "      <th>-1.783e-05</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.33518</td>\n",
       "      <td>-14.134</td>\n",
       "      <td>7.3409</td>\n",
       "      <td>0.99856</td>\n",
       "      <td>0.87461</td>\n",
       "      <td>0.80615</td>\n",
       "      <td>-0.024650</td>\n",
       "      <td>0.17291</td>\n",
       "      <td>-0.331390</td>\n",
       "      <td>0.296080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>2.032200e-04</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.53979</td>\n",
       "      <td>-14.600</td>\n",
       "      <td>7.5290</td>\n",
       "      <td>1.25120</td>\n",
       "      <td>0.65054</td>\n",
       "      <td>0.73118</td>\n",
       "      <td>0.036801</td>\n",
       "      <td>0.25653</td>\n",
       "      <td>-0.289080</td>\n",
       "      <td>0.337880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>5.168800e-07</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.96780</td>\n",
       "      <td>-15.274</td>\n",
       "      <td>7.1488</td>\n",
       "      <td>1.34540</td>\n",
       "      <td>0.83254</td>\n",
       "      <td>0.91121</td>\n",
       "      <td>0.125130</td>\n",
       "      <td>0.32822</td>\n",
       "      <td>-0.290950</td>\n",
       "      <td>0.342770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-2.219200e-05</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.12280</td>\n",
       "      <td>-12.564</td>\n",
       "      <td>7.0406</td>\n",
       "      <td>0.93019</td>\n",
       "      <td>1.26220</td>\n",
       "      <td>0.11738</td>\n",
       "      <td>0.570680</td>\n",
       "      <td>0.26390</td>\n",
       "      <td>0.138620</td>\n",
       "      <td>0.787870</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.084600e-04</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.32150</td>\n",
       "      <td>-12.240</td>\n",
       "      <td>6.9704</td>\n",
       "      <td>0.70072</td>\n",
       "      <td>1.24620</td>\n",
       "      <td>0.18263</td>\n",
       "      <td>0.550100</td>\n",
       "      <td>0.16563</td>\n",
       "      <td>0.112470</td>\n",
       "      <td>0.827640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>-1.406000e-05</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7518</th>\n",
       "      <td>-6.87800</td>\n",
       "      <td>-19.030</td>\n",
       "      <td>3.4972</td>\n",
       "      <td>0.62311</td>\n",
       "      <td>0.45905</td>\n",
       "      <td>0.49920</td>\n",
       "      <td>0.092995</td>\n",
       "      <td>0.17074</td>\n",
       "      <td>-0.152760</td>\n",
       "      <td>0.087835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>6.846800e-06</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>-7.18810</td>\n",
       "      <td>-19.168</td>\n",
       "      <td>3.3892</td>\n",
       "      <td>0.62209</td>\n",
       "      <td>0.47292</td>\n",
       "      <td>0.49791</td>\n",
       "      <td>0.094041</td>\n",
       "      <td>0.19643</td>\n",
       "      <td>-0.106620</td>\n",
       "      <td>0.125620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>-6.001700e-05</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>-7.21280</td>\n",
       "      <td>-19.147</td>\n",
       "      <td>3.4621</td>\n",
       "      <td>0.66061</td>\n",
       "      <td>0.39095</td>\n",
       "      <td>0.43684</td>\n",
       "      <td>0.136610</td>\n",
       "      <td>0.22249</td>\n",
       "      <td>-0.165220</td>\n",
       "      <td>0.065559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-6.587000e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7521</th>\n",
       "      <td>-6.92500</td>\n",
       "      <td>-19.096</td>\n",
       "      <td>3.5545</td>\n",
       "      <td>0.75446</td>\n",
       "      <td>0.40096</td>\n",
       "      <td>0.36889</td>\n",
       "      <td>0.082292</td>\n",
       "      <td>0.18993</td>\n",
       "      <td>-0.187880</td>\n",
       "      <td>0.074205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>1.125700e-04</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7522</th>\n",
       "      <td>-7.41540</td>\n",
       "      <td>-19.403</td>\n",
       "      <td>3.2727</td>\n",
       "      <td>0.75611</td>\n",
       "      <td>0.55089</td>\n",
       "      <td>0.50017</td>\n",
       "      <td>0.169750</td>\n",
       "      <td>0.28818</td>\n",
       "      <td>-0.066786</td>\n",
       "      <td>0.178660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>1.294000e-04</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7523 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      -0.55307  -13.949  7.2276  0.81332  0.81042  0.57891  0.057156  0.30691  \\\n",
       "0     -0.33518  -14.134  7.3409  0.99856  0.87461  0.80615 -0.024650  0.17291   \n",
       "1     -0.53979  -14.600  7.5290  1.25120  0.65054  0.73118  0.036801  0.25653   \n",
       "2     -0.96780  -15.274  7.1488  1.34540  0.83254  0.91121  0.125130  0.32822   \n",
       "3      1.12280  -12.564  7.0406  0.93019  1.26220  0.11738  0.570680  0.26390   \n",
       "4      1.32150  -12.240  6.9704  0.70072  1.24620  0.18263  0.550100  0.16563   \n",
       "...        ...      ...     ...      ...      ...      ...       ...      ...   \n",
       "7518  -6.87800  -19.030  3.4972  0.62311  0.45905  0.49920  0.092995  0.17074   \n",
       "7519  -7.18810  -19.168  3.3892  0.62209  0.47292  0.49791  0.094041  0.19643   \n",
       "7520  -7.21280  -19.147  3.4621  0.66061  0.39095  0.43684  0.136610  0.22249   \n",
       "7521  -6.92500  -19.096  3.5545  0.75446  0.40096  0.36889  0.082292  0.18993   \n",
       "7522  -7.41540  -19.403  3.2727  0.75611  0.55089  0.50017  0.169750  0.28818   \n",
       "\n",
       "      -0.28209   0.34901  ...  -1.2757e-05  -1.791e-05  0.00014175  \\\n",
       "0    -0.331390  0.296080  ...     0.000242    0.000437    0.000095   \n",
       "1    -0.289080  0.337880  ...     0.000097    0.000036    0.000028   \n",
       "2    -0.290950  0.342770  ...    -0.000004   -0.000021   -0.000116   \n",
       "3     0.138620  0.787870  ...    -0.000087   -0.000079   -0.000082   \n",
       "4     0.112470  0.827640  ...    -0.000053    0.000042    0.000135   \n",
       "...        ...       ...  ...          ...         ...         ...   \n",
       "7518 -0.152760  0.087835  ...     0.000094    0.000196    0.000139   \n",
       "7519 -0.106620  0.125620  ...     0.000074   -0.000006    0.000001   \n",
       "7520 -0.165220  0.065559  ...     0.000078    0.000066    0.000048   \n",
       "7521 -0.187880  0.074205  ...    -0.000164   -0.000120   -0.000009   \n",
       "7522 -0.066786  0.178660  ...    -0.000032   -0.000072   -0.000025   \n",
       "\n",
       "      0.00018104  2.7085e-05  1.9801e-05  1.6102e-05    1.5949e-05  \\\n",
       "0      -0.000089   -0.000200    0.000036    0.000073  2.032200e-04   \n",
       "1       0.000031    0.000075    0.000067    0.000049  5.168800e-07   \n",
       "2      -0.000025   -0.000018    0.000013   -0.000015 -2.219200e-05   \n",
       "3       0.000076    0.000107    0.000125    0.000071  1.084600e-04   \n",
       "4       0.000108    0.000032   -0.000088   -0.000079 -1.406000e-05   \n",
       "...          ...         ...         ...         ...           ...   \n",
       "7518    0.000110    0.000007   -0.000074   -0.000023  6.846800e-06   \n",
       "7519    0.000045    0.000014   -0.000071   -0.000096 -6.001700e-05   \n",
       "7520   -0.000059   -0.000062   -0.000013   -0.000065 -6.587000e-05   \n",
       "7521    0.000020    0.000051    0.000129    0.000142  1.125700e-04   \n",
       "7522    0.000082   -0.000022   -0.000044    0.000086  1.294000e-04   \n",
       "\n",
       "      -1.783e-05  0  \n",
       "0       0.000179  0  \n",
       "1       0.000017  0  \n",
       "2      -0.000059  0  \n",
       "3       0.000044  0  \n",
       "4      -0.000073  0  \n",
       "...          ... ..  \n",
       "7518   -0.000093  2  \n",
       "7519   -0.000132  2  \n",
       "7520    0.000004  2  \n",
       "7521    0.000012  2  \n",
       "7522    0.000119  2  \n",
       "\n",
       "[7523 rows x 43 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('C:\\\\Users\\\\anjal\\\\Desktop\\\\project-audio-spoofing\\\\frontend\\\\G_TRAIN.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "630ee8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:43].values\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b90d6a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# oversample = SMOTE()\n",
    "# X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1510f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8a81ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7523, 43)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9d719c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc4af1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 323489  // 43\n",
    "x\n",
    "X=X.reshape(7523, 43,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b697b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "110d684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91e4451b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "753/753 [==============================] - 40s 47ms/step - loss: 0.3541 - accuracy: 0.4902\n",
      "Epoch 2/50\n",
      "753/753 [==============================] - 37s 49ms/step - loss: 0.0611 - accuracy: 0.5776\n",
      "Epoch 3/50\n",
      "753/753 [==============================] - 42s 56ms/step - loss: 0.0266 - accuracy: 0.5875\n",
      "Epoch 4/50\n",
      "753/753 [==============================] - 48s 64ms/step - loss: 0.0177 - accuracy: 0.5877\n",
      "Epoch 5/50\n",
      "753/753 [==============================] - 48s 64ms/step - loss: 0.0146 - accuracy: 0.5877\n",
      "Epoch 6/50\n",
      "753/753 [==============================] - 48s 64ms/step - loss: 0.0128 - accuracy: 0.5877\n",
      "Epoch 7/50\n",
      "753/753 [==============================] - 49s 64ms/step - loss: 0.0116 - accuracy: 0.5877\n",
      "Epoch 8/50\n",
      "753/753 [==============================] - 49s 66ms/step - loss: 0.0104 - accuracy: 0.5877\n",
      "Epoch 9/50\n",
      "753/753 [==============================] - 49s 65ms/step - loss: 0.0098 - accuracy: 0.5877\n",
      "Epoch 10/50\n",
      "753/753 [==============================] - 49s 64ms/step - loss: 0.0087 - accuracy: 0.5877\n",
      "Epoch 11/50\n",
      "753/753 [==============================] - 55s 73ms/step - loss: 0.0076 - accuracy: 0.5877\n",
      "Epoch 12/50\n",
      "753/753 [==============================] - 41s 55ms/step - loss: 0.0074 - accuracy: 0.5877\n",
      "Epoch 13/50\n",
      "753/753 [==============================] - 40s 53ms/step - loss: 0.0069 - accuracy: 0.5877\n",
      "Epoch 14/50\n",
      "753/753 [==============================] - 40s 53ms/step - loss: 0.0066 - accuracy: 0.5877\n",
      "Epoch 15/50\n",
      "753/753 [==============================] - 40s 54ms/step - loss: 0.0056 - accuracy: 0.5877\n",
      "Epoch 16/50\n",
      "753/753 [==============================] - 42s 56ms/step - loss: 0.0052 - accuracy: 0.5877\n",
      "Epoch 17/50\n",
      "753/753 [==============================] - 40s 53ms/step - loss: 0.0052 - accuracy: 0.5877\n",
      "Epoch 18/50\n",
      "753/753 [==============================] - 41s 54ms/step - loss: 0.0048 - accuracy: 0.5877\n",
      "Epoch 19/50\n",
      "753/753 [==============================] - 39s 52ms/step - loss: 0.0044 - accuracy: 0.5877\n",
      "Epoch 20/50\n",
      "753/753 [==============================] - 41s 54ms/step - loss: 0.0042 - accuracy: 0.5875\n",
      "Epoch 21/50\n",
      "753/753 [==============================] - 37s 50ms/step - loss: 0.0042 - accuracy: 0.5877\n",
      "Epoch 22/50\n",
      "753/753 [==============================] - 37s 49ms/step - loss: 0.0038 - accuracy: 0.5877\n",
      "Epoch 23/50\n",
      "753/753 [==============================] - 37s 49ms/step - loss: 0.0036 - accuracy: 0.5877\n",
      "Epoch 24/50\n",
      "753/753 [==============================] - 40s 53ms/step - loss: 0.0037 - accuracy: 0.5877\n",
      "Epoch 25/50\n",
      "753/753 [==============================] - 40s 53ms/step - loss: 0.0037 - accuracy: 0.5877\n",
      "Epoch 26/50\n",
      "753/753 [==============================] - 40s 54ms/step - loss: 0.0033 - accuracy: 0.5877\n",
      "Epoch 27/50\n",
      "753/753 [==============================] - 38s 50ms/step - loss: 0.0033 - accuracy: 0.5877\n",
      "Epoch 28/50\n",
      "753/753 [==============================] - 37s 49ms/step - loss: 0.0032 - accuracy: 0.5877\n",
      "Epoch 29/50\n",
      "753/753 [==============================] - 40s 53ms/step - loss: 0.0036 - accuracy: 0.5877\n",
      "Epoch 30/50\n",
      "753/753 [==============================] - 39s 52ms/step - loss: 0.0032 - accuracy: 0.5877\n",
      "Epoch 31/50\n",
      "753/753 [==============================] - 41s 54ms/step - loss: 0.0032 - accuracy: 0.5877\n",
      "Epoch 32/50\n",
      "753/753 [==============================] - 40s 54ms/step - loss: 0.0031 - accuracy: 0.5877\n",
      "Epoch 33/50\n",
      "753/753 [==============================] - 40s 53ms/step - loss: 0.0030 - accuracy: 0.5877\n",
      "Epoch 34/50\n",
      "753/753 [==============================] - 39s 52ms/step - loss: 0.0032 - accuracy: 0.5877\n",
      "Epoch 35/50\n",
      "753/753 [==============================] - 39s 51ms/step - loss: 0.0031 - accuracy: 0.5877\n",
      "Epoch 36/50\n",
      "753/753 [==============================] - 42s 55ms/step - loss: 0.0033 - accuracy: 0.5877\n",
      "Epoch 37/50\n",
      "753/753 [==============================] - 41s 54ms/step - loss: 0.0031 - accuracy: 0.5877\n",
      "Epoch 38/50\n",
      "753/753 [==============================] - 43s 58ms/step - loss: 0.0032 - accuracy: 0.5877\n",
      "Epoch 39/50\n",
      "753/753 [==============================] - 41s 55ms/step - loss: 0.0029 - accuracy: 0.5877\n",
      "Epoch 40/50\n",
      "753/753 [==============================] - 40s 53ms/step - loss: 0.0029 - accuracy: 0.5877\n",
      "Epoch 41/50\n",
      "753/753 [==============================] - 41s 55ms/step - loss: 0.0030 - accuracy: 0.5877\n",
      "Epoch 42/50\n",
      "753/753 [==============================] - 41s 54ms/step - loss: 0.0030 - accuracy: 0.5877\n",
      "Epoch 43/50\n",
      "753/753 [==============================] - 43s 57ms/step - loss: 0.0029 - accuracy: 0.5877\n",
      "Epoch 44/50\n",
      "753/753 [==============================] - 41s 54ms/step - loss: 0.0029 - accuracy: 0.5877\n",
      "Epoch 45/50\n",
      "753/753 [==============================] - 41s 54ms/step - loss: 0.0029 - accuracy: 0.5877\n",
      "Epoch 46/50\n",
      "753/753 [==============================] - 42s 55ms/step - loss: 0.0029 - accuracy: 0.5877\n",
      "Epoch 47/50\n",
      "753/753 [==============================] - 40s 54ms/step - loss: 0.0029 - accuracy: 0.5877\n",
      "Epoch 48/50\n",
      "753/753 [==============================] - 41s 54ms/step - loss: 0.0028 - accuracy: 0.5877\n",
      "Epoch 49/50\n",
      "753/753 [==============================] - 41s 54ms/step - loss: 0.0028 - accuracy: 0.5877\n",
      "Epoch 50/50\n",
      "753/753 [==============================] - 41s 54ms/step - loss: 0.0027 - accuracy: 0.5877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x270d315ac70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = keras.models.Sequential()\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (43, 1)))\n",
    "\n",
    "#regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (67, 1)))\n",
    "\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics=['accuracy'])\n",
    "\n",
    "#regressor.fit(X_train, y_train, validation_data= (X_test,y_test),epochs = 50, batch_size = 32)\n",
    "regressor.fit(X, y, epochs = 50, batch_size = 10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ed38afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dtf=pd.read_csv('C:\\\\Users\\\\anjal\\\\Desktop\\\\project-audio-spoofing\\\\frontend\\\\G_TEST.csv')\n",
    "dtf\n",
    "Xt = dtf.iloc[:, 0:43].values\n",
    "\n",
    "yt = dtf.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45e8d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Xt = np.reshape(Xt, (Xt.shape[0], Xt.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76ea380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_x=regressor.predict(Xt) \n",
    "\n",
    "# classes_x=np.argmax(predict_x,axis=1)\n",
    "prediction1=regressor.predict(Xt)\n",
    "prediction1=regressor.predict((Xt) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f39c92df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333/333 [==============================] - 8s 21ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "score=regressor.evaluate(Xt, yt)\n",
    "print(\"%s: %.2f%%\" % (regressor.metrics_names[1], score[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1888512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for Test Set is 100.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3276\n",
      "           1       1.00      1.00      1.00      7354\n",
      "\n",
      "    accuracy                           1.00     10630\n",
      "   macro avg       1.00      1.00      1.00     10630\n",
      "weighted avg       1.00      1.00      1.00     10630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import precision_score\n",
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import roc_curve\n",
    "\n",
    "# results=confusion_matrix(yt, prediction1)\n",
    "# print(\"confusion matrix\", results)\n",
    "\n",
    "# accuracy = accuracy_score(yt, prediction1)\n",
    "# print('Accuracy: %f' % accuracy)\n",
    "\n",
    "# precision = precision_score(yt, prediction1)\n",
    "# print('Precision: %f' % precision)\n",
    "# # recall: tp / (tp + fn)\n",
    "# recall = recall_score(yt, prediction1)\n",
    "# print('Recall: %f' % recall)\n",
    "# # f1: 2 tp / (2 tp + fp + fn)\n",
    "# f1 = f1_score(yt, prediction1)\n",
    "# print('F1 score: %f' % f1)\n",
    "\n",
    "# fpr, tpr, threshold = roc_curve(yt,prediction1, pos_label=1)\n",
    "# fnr = 1 - tpr\n",
    "# eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "# EER = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "# print(eer_threshold)\n",
    "# print(\"EER = \", EER)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_acc = accuracy_score(yt, prediction1)\n",
    "print(\"The Accuracy for Test Set is {}\".format(test_acc*100))\n",
    "print(classification_report(yt, prediction1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90a2b8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm=confusion_matrix(yt, prediction1)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Confusion Matrix\")\n",
    "sns.heatmap(cm, annot=True,fmt='d', cmap='Blues')\n",
    "plt.ylabel(\"Actual Values\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f3948af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "EER =  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(yt, prediction1, pos_label=1)\n",
    "fnr = 1 - tpr\n",
    "eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "EER = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "print(eer_threshold)\n",
    "print(\"EER = \", EER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace1a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
